\documentclass[12pt]{report}
%include polycode.fmt
\include{preamble}
\begin{document}
\include{document.preamble}

%% Float parameters
\renewcommand{\textfraction}{0.1}
\renewcommand{\topfraction}{0.9}

\chapter{Dataflow Optimization}
\label{ref_chapter_background}

%% A short section giving the history of dataflow optimization techniques
%% and basic concepts.

% Describe dataflow analysis in general terms and defines key
% concepts: basic blocks, control flow, facts, and
% rewrites. Bind/Return elimination is used as an an example.

The term ``program optimization'' refers to the process of
transforming a program without changing its semantics (i.e., meaning),
while at the same time ``improving'' its behavior.  For example, an
optimized program may run faster, use less memory, consume less power,
or some sense perform ``better'' than the unoptimized
program. Optimizations can be performed ``by hand,'' while writing
the program, or automatically by a compiler. 

``Dataflow analysis'' (or ``dataflow optimization''), first introduced
by Gary Kildall \citep{Kildall1973}, refers to an algorithm for
applying an ``optimizing function'' to a given program. In itself it
does not give a specific optimization; rather, it gives a technique
for applying many different optimizations. In today's terms, dataflow
analysis treats a program as a ``control-flow graph'', applies a
``transfer'' function to compute ``facts'' about the execution of the
program, and then applies a ``rewriting'' function to transform the
program based on those facts. Dataflow analysis is now considered
standard technique and can be found in most compiler textbooks.

\section{Dataflow Concepts}

%% Control-flow graph

The \emph{control-flow graph} (CFG) of a program shows how the program
may be executed: which statements follow one another, branches that
can be taken, loops that may execute, and possible ways the program
can terminate.

\begin{myfig}[th]
\begin{tabular}{cc}
\subfloat{\input{lst_back1}%%
  \label{fig_back1_a}} \vline & 
\subfloat{\input{lst_back2}%%
  \label{fig_back1_b}} \\
\subref{fig_back1_a} & \subref{fig_back1_b} \\\rule{0pt}{24pt}
\end{tabular}
\caption{(\emph{a}): A C-language program fragment. (\emph{b}): The
  \emph{control-flow graph} (CFG) for the program.}
\label{fig_back1}
\end{myfig}

Figure \ref{fig_back1} shows a simple C program and the associated
CFG. Each \emph{node} in the graph represents a statement in the
original program. In
the figure, node 7 represents the #print# statement at line
\ref{lst_back1_print}. Node 1, the \emph{entry point}, designates
where program execution begins. Nothing precedes the entry point, and
only one entry point exists in the graph.\footnote{Multiple entry
  points can be defined but it only complicates later
  analysis. Instead, we can always transform a graph with multiple
  entry points into one with a single entry point by creating one node
  that precedes all existing entry points. That node can then
  determine which entry point to execute, based on whatever conditions
  were orignally used to select the individual entry point.} 

The \emph{directed edge} from node 2 to node 3 shows how the
assignments on line \ref{lst_back1_assign} precede the test on line
\ref{lst_back1_test}. Edges show the order in which nodes
execute. \emph{Predecessor} nodes always execute before
\emph{successor} nodes, except in the presence of loops.

A node followed by multiple successors (i.e., where multiple edges
leave the node) represents a \emph{branch} or \emph{conditional}. Node
3 represents the test on line \ref{lst_back1_test}, which can branch to
line \ref{lst_back1_test_true} or line \ref{lst_back1_test_false}. The
edges leaving node 3 show that execution can branch to either node 4
or node 5.

The #printf# statement on line \ref{lst_back1_print} executes
regardless of the result of the test on \ref{lst_back1_test}, which
the graph shows by making both nodes 4 and 5 predecessors of node
6. After line \ref{lst_back1_print}, the program ends. Node 7, an
\emph{exit point}, shows where execution terminates. Unlike entry
points, multiple exit points can exist in a graph.

%% Basic blocks

%% In & Out facts

%% Direction & Transfer Function

Dataflow analysis applies a ``transfer function'' to each node in the
CFG to compute ``facts'' about the program's state before and after
the execution of each node. The facts computed and the transfer
function used depend on the specific optimization, but dataflow
analysis always applies them in the same way. Each node has two sets
of facts -- ``in'' and ``out.'' The transfer function uses the ``in''
facts to compute ``out'' facts for a node. ``Out'' facts on a node
become ``in'' facts on the node analyzed next.  If the CFG for a
program contains loops, then ``in'' facts for a node may change based
on later ``out'' facts. The transfer function will be applied
repeatedly until the facts stop changing -- they reach a ``fixed
point.''

%% Meet operator
If the CFG for a program contains nodes with multiple predecessors,
``in'' facts must be combined in some way. The ``meet'' operator for
each optimization combines facts. Usually, the operator takes the
intersection or union of all the facts. Intersection implies the
analysis computes something is true for \emph{all} incoming paths. Union
implies computing something for \emph{any} incoming path.

Because we represent the CFG for a program as a directed graph, we can
choose which direction to traverse the CFG -- forwards or backwards.
When traversing forward, we usually compute facts about program
execution past a certain point (e.g., does a variable's value
change?); a backwards analysis computes facts up to a certain point
(e.g., what variables will be referenced following a given
statement?). Where a forwards analysis begins at the entry point(s)
for the CFG, a backwards analysis begins at the exit points.


%% Iterative Analysis & Fixed points

%% Rewrite based on analysis
Direction, the meet operator, facts, and the transfer function
together define the optimizing function applied by dataflow analysis
for a particular optimization. The result of the analysis is then used
to alter, or ``rewrite,'' the CFG. The meaning of the new program will
not be different than the old, but it will behave differently: execute
faster, use less memory, or whatever characteristic the optimization
should improve.

\section{Example: Dead-Code Elimination}

Consider Figure \ref{fig_back2}, again showing a C-language fragment.
After assignment on line \ref{fig_back2_dead_line}, #b# is not
referenced. Removing the #b# will not affect the program and,
if nothing else, will reduce the size of the program. It may even make
it run faster or use less memory. We call this optimization
\emph{dead-code elimination}.

\begin{myfig}[ht]
\begin{minipage}{1in}
  \begin{Verbatim}[numbers=left,commandchars=\\\{\}]
    a = 1;
    b = a + 1;\label{fig_back2_dead_line}
    return a + 1;
  \end{Verbatim}
\end{minipage}
\caption{A C-language fragment illustrating \emph{dead code}. After
assignment on line \ref{fig_back2_dead_line}, \verb=b= is not used
and can be considered ``dead.''}
\label{fig_back2}
\end{myfig}

Of course, people do not normally write programs with such obviously
useless statements, but other compiler optimizations can produce (or
leave behind) many such statements. \emph{Uncurrying}, described in
Chapter \ref{ref_chapter_uncurrying}, in fact depends on dead-code elmination.

To eliminate the assignment like that on line
\ref{fig_back2_dead_line}, we really need to determine which variables
are referenced after assignment. Such variables are ``live''; if a
variable is \emph{not} live, then it is dead. We use this ``liveness''
analysis to determine if a particular assignment is dead.

To determine if a variable is live, we need to know if it is
referenced after assignment.  Such variables make up the \emph{the
  live set} which we can compute between each statement. To compute
the live set, we can choose to traverse the CFG for the program forwards or
backwards.  In the forwards case, we must track each assignment and
determine, when we exit the fragment, if the variable was used
afterwards. In general we would need to track every assignment until
our traversal finished. However, if we traverse backwards, we only
need to note any reference to a variable. When we see an assignment to
a variable \emph{not} in our live set, we know it will not be
referenced afterwards. Therefore we compute ``liveness'' using a
backwards travesal over the CFG.

\begin{myfig}[th]
\begin{minipage}{2in}
\begin{Verbatim}[commandchars=\\\{\}]
       E
       ||      
       v
     -----
    ||a = 1||    \emph{live:}  \ensuremath{\emptyset}
     -----
       ||      
       V
   ---------
  ||b = a + 1||  \emph{live:} \{a\}  
   ---------
       ||      
       V
  ------------
 ||return a + 1|| \emph{live:} \{a\}
  ------------
       ||      
       X          \emph{live:}  \ensuremath{\emptyset}
\end{Verbatim}
\end{minipage}
\caption{The CFG for our example program, annotated with the live
set for each node.}
\label{fig_back3}
\end{myfig}

Figure \ref{fig_back3} shows the CFG for this example, with annotations
between each statement showing the live set. Though
execution follows the arrows in the CFG, our analysis proceeds
backwards. For example, the input to node 2 is the live set computed
for node 3 (``$\{a\}$'' in this case).

Our transfer function computes the live set based on \emph{uses} and
\emph{definitions} in a statement. Any reference (or use) of a
variable goes into the live set. Any assignment (or definition) of a
variable removes it from the live set. We can then define our transfer
function, |live|, for a statement as:

\begin{align}
  & |live|(s) = (\Varid{in}(s) \cup |use|(s)) - |def|(s), \label{eqn_back1} \\
\intertext{where}
  & s     & \text{Statement considered.} \notag\\
  & |use|(s) &  \text{Set of variables used in $s$}. \notag\\
  & |def|(s) & \text{Variable assigned to in $s$ (a singleton set)}. \notag\\
  & |in|(s) & \text{Live variables computed for $s$' successor}. \notag
\end{align}

Table \ref{tbl_back1} shows the |use| and |def| sets for each
statement. The live set computed, |live|, becomes the input, |in|, for
the statement's predecessor. We include the exit node (``#X#'') in the
table to show the initial value of |in| for the last statement --
$\emptyset$, the empty set. Our analysis then works backwards through the
program. If our program (and its CFG) contained any loops, we would
need to run this algorithm multiple times, until the live set for each
statement reached a fixed point.

\begin{table}
  \centering
  \begin{tabular}{lcccc}
    $s$ & $|use|(s)$ & $|def|(s)$ & $|in|(s)$ &  $|live|(s)$ \\
    \cmidrule(r){1-1}\cmidrule(r){2-2}\cmidrule(r){3-3}\cmidrule(r){4-4}\cmidrule(r){5-5}
    #X# & & & & $\emptyset$ \\
    #return a + 1# & $\{a\}$ & $\emptyset$ & $\emptyset$ & $\{a\}$ \\
    #b = a + 1# & $\{a\}$ & $\{b\}$ & $\{a\}$ & $\{a\}$ \\
    #a = 1# & $\emptyset$ & $\{a\}$ & $\{a\}$ & $\emptyset$ \\
    \bottomrule
  \end{tabular}
  \caption{The $|use|$, $|def|$ and $|live|$ sets computed using equation \ref{eqn_back1} for our example program.}
  \label{tbl_back1}
\end{table}

With the live set computed for each statement, our analysis can now
determine which statements to eliminate. Only nodes 1 and 2 in Figure
\ref{fig_back3} perform an assignment. The live set for node 1 (``#a = 1#'')
contains #a#, so we do not eliminate it. In node 2 (``#b = a + 1#''),
the live set does \emph{not} contain #b#. Therefore, we can eliminate
node 2, giving us a new program without any dead code:

\begin{Verbatim}
a = 1;
return a + 1;
\end{Verbatim}

\section{Conclusion}

This chapter gave an overview of \emph{dataflow optimization}, a
technique we used extensively in our work. The dataflow
\emph{algorithm} gives a general technique for applying an
\emph{optimizing function} to the \emph{control flow graph} (CFG)
representing a give program. The optimizing function computes
\emph{facts} about each node in the graph, using a \emph{transfer}
function to turn input facts into output facts. The CFG can be
traversed forwards or backwards (depending on the particular
optimization), and it may need to be traversed many times until the
computed facts reach a \emph{fixed point}.  Each optimization defines
a specific \emph{meet operator} that combines facts for nodes with
multiple inputs. Finally, the facts computed are used to
\emph{rewrite} the CFG, transforming the program so it still has the
same meaning, but behaves better, according to the optimization used.


%% \subsection{Basic Blocks and Control-Flow Graphs}

%% A dataflow optimization operates over a ``control-flow graph'' (CFG)
%% of the program -- a directed graph where edges encode branches or
%% jumps and nodes represent statements. Programs run by entering a node
%% from a predecessor, executing the statements in turn, and exiting the
%% node to a successor. Multiple successors imply a conditional branch,
%% though the program can only choose one. A special ``entry'' node, with
%% no predecssors, exists to give the program a starting point.

%% The statements in each node must define a ``basic block,'' which means
%% there can only be one entry and one exit to the node. Each
%% predeccessor starts at the same statement; execution cannot start in
%% the ``middle'' of the statements in the node. Each successor also
%% leaves from the same instruction, so only one ``branch'' can exist in
%% each node.

%% For example, consider the ``fall-through'' implied by the use of #case#
%% statements in this C-language program fragment:

%% \begin{verbatim}
%%   switch(i) {
%%   case 1:
%%     printf("1");
%%     break;
%%   case 2:
%%     printf("2");
%%   case 3:
%%     printf("3");
%%   }
%% \end{verbatim}

%% \begin{figure}[h]
%% \begin{verbatim}
%%    A
%%   switch   ----<-
%%   | |  |  |      |
%%   | |  |  v C    ^
%%   | |   ->case 3 |
%%   | |     |      |
%%   | |      ->----_--
%%   | | B          |  |
%%   |  ->case 2 ->-   v
%%   |                 |
%%   |   D       ----<-
%%    ->case 1  |
%%      |       v
%%      v       |
%%    --+-----<-
%%   |
%%    -> ...
%% \end{verbatim}
%% \caption{CFG illustrating \emph{fall-through} allowed by the
%%   C-language \texttt{switch} statement.}
%% \label{switchCfgEg}
%% \end{figure}

%% Figure \ref{switchCfgEg} shows a CFG for this fragment. Execution
%% begins at node A. Node C has two predeccessors: A and B. The edge
%% between Node B and C represents fall-through from the second to third
%% case. They cannot be combined because the node would need two distinct
%% entry points. Encoding a program into basic blocks usually involves
%% inserting similar branches. The CFG makes explicit control--flow that
%% exists by implication in the source program.

%% \subsection{Direction, Facts and Rewrites}

%% \subsection{Example: Bind/Return Collapse}

%% Dataflow optimizations transform the CFG representation of a program,
%% with the goal of making a faster (or smaller, or more efficient, etc.)
%% program. Dataflow computes a set of ``entry'' assumptions and ``exit''
%% facts for each node in the graph. Facts for one node become
%% assumptions for the nodes' successors (thus the term
%% ``dataflow''). The algorithm iteratves over the entire graph until a
%% fixed point is reached -- that is, facts and assumptions no longer
%% change. The computed facts can then be used to transform the graph.

%% \emph{Constant propagation example -- or something more functional?}

%% \emph{Introduce forward and backwards dataflow.}

% What does dataflow mean?

% How do you use it?

% Example

\end{document}
