\documentclass[12pt]{report}
%include polycode.fmt
\include{preamble}
\begin{document}
\include{document.preamble}
\newcounter{nodeCounter}[subfigure]
%% Float parameters
\renewcommand{\textfraction}{0.1}
\renewcommand{\topfraction}{0.9}
%% in and out sets
\newcommand{\inE}{\emph{in}\xspace}
\newcommand{\out}{\emph{out}\xspace}
\newcommand{\In}{\emph{In}\xspace}
\newcommand{\Out}{\emph{Out}\xspace}

\chapter{Dataflow Optimization}
\label{ref_chapter_background}

%% A short section giving the history of dataflow optimization techniques
%% and basic concepts.

% Describe dataflow analysis in general terms and defines key
% concepts: basic blocks, control flow, facts, and
% rewrites. Bind/Return elimination is used as an an example.

The term ``program optimization'' refers to the process of
transforming a program without changing its semantics (i.e., meaning),
while at the same time ``improving'' its behavior.  For example, an
optimized program may run faster, use less memory, consume less power,
or some sense perform ``better'' than the unoptimized
program. Optimizations can be performed ``by hand,'' while writing
the program, or automatically by a compiler. 

``Dataflow analysis'' (or ``dataflow optimization''), first introduced
by Gary Kildall \citep{Kildall1973}, refers to an algorithm for
applying an ``optimizing function'' to a given program. In itself it
does not give a specific optimization; rather, it describes a method
for applying many different optimizations. Since that time, a rich
body of research and literature has been done, extending and refining
Kilall's original description (\cite{SomePaperXX},
\cite{SomeBookXX}). Dataflow analysis is now considered standard
technique and can be found in most compiler textbooks.

This chapter covers the concepts necessary to understand dataflow
analysis. Section \ref{sec_back1} describes control-flow graphs, a
data structure for representing programs. We discuss facts and the
``meet'' operator in Section \ref{sec_back4}.  Section \ref{sec_back5}
describes transfer functions and the difference between a ``forwards''
and ``backwards'' analysis. We describe the iterative nature of
dataflow analysis in Section \ref{sec_back6}, showing how we can
analyze loops and other complicated control structures. Section
\ref{sec_back7} discusses how we rewrite programs based on the
dataflow analysis performed. We then give an extended example
illustring \emph{dead-code elimination} in Section
\ref{sec_back2}. Finally, we summarize our chapter in Section
\ref{sec_back9}.

\section{Control-Flow Graphs}
\label{sec_back1}
%% Control-flow graph

The \emph{control-flow graph} (CFG) of a program shows how it
may be executed: which statements follow one another, branches that
can be taken, loops that may execute, and possible ways the program
can terminate.

\begin{myfig}[th]
\begin{tabular}{cc}
\subfloat{\input{lst_back1}%%
  \label{fig_back1_a}} \vline & 
\subfloat{\input{lst_back2}%%
  \label{fig_back1_b}} \\
\subref{fig_back1_a} & \subref{fig_back1_b} 
\end{tabular}
\caption{(\emph{a}): A C-language program fragment. (\emph{b}): The
  \emph{control-flow graph} (CFG) for the program.}
\label{fig_back1}
\end{myfig}

Figure \ref{fig_back1} shows a simple C program and its CFG. Each
\emph{node} in the graph represents a statement in the original
program. For example, nodes \ref{lst_back2_assigna} and
\ref{lst_back2_assignb} represent the assignment statements on line
\ref{lst_back1_assign}. Node \ref{lst_back2_entry}, the \emph{entry
  point}, designates where program execution begins. Nothing precedes
the entry point, and only one entry point exists in the graph. After
line \ref{lst_back1_print}, the program ends. Node
\ref{lst_back2_exit}, an \emph{exit point}, shows where execution
terminates. Unlike entry points, multiple exit points can exist in a
graph.

The \emph{directed edges} from node \ref{lst_back2_assigna} to node
\ref{lst_back2_assignb}, and from node \ref{lst_back2_assignb} to node
\ref{lst_back2_test} shows how the assignments on line
\ref{lst_back1_assign} precede the test on line
\ref{lst_back1_test}. Edges show the order in which nodes
execute. \emph{Predecessor} nodes always execute before
\emph{successor} nodes (except in the presence of loops).

The edges leaving node \ref{lst_back2_test} (representing the test
``\verb=if(a > b)='') show that execution can branch to either node
\ref{lst_back2_true} ($a > b$) or node \ref{lst_back2_false} ($a \leq
b$). A node followed by multiple successors (i.e., where multiple
edges leave the node) represents a \emph{branch} or \emph{conditional}
statement. Any one of the successor nodes may execute following the
conditional statement, depending on the condition tested.

Conversely, a node with multiple predecessors represents the
destination of multiple execution paths. The #printf# statement on
line \ref{lst_back1_print} always executes, regardless of the result
of the test on \ref{lst_back1_test}. Our CFG represents this by making
nodes \ref{lst_back2_true} and \ref{lst_back2_false} predecessors of
node \ref{lst_back2_print}.

\section{Basic Blocks}
\label{sec_back3}

%% Basic blocks
Consider the C-language fragment and CFGs in Figure
\ref{fig_back4}. Part \subref{fig_back4_b} shows the CFG for lines
\ref{lst_back3_start} -- \ref{lst_back3_end} in part
\subref{fig_back4_a}: a long, straight sequence of nodes, one after
another. Collapsing those nodes into one, as in part
\subref{fig_back4_c}, does not lose information and gives a more
compact representation. 

\afterpage{\clearpage{\input{fig_back4}}\clearpage}

Each node in Figure \ref{fig_back4_c} represents a \emph{basic block}:
a sequence of statements with one entry, one exit, and no branches
in-between. Execution cannot start in the ``middle'' of the block, nor
can it branch anywhere but at the end of the block. Basic blocks are a
widely used representation for programs, found in standard compiler
textbooks (\citep{AhoXX}, \citep{MunchXX}, \citep{AppelXX}).

A basic block can consist of one statement -- a \emph{trivial}
block. For example, the nodes in Figures \ref{fig_back4_b} and
\ref{fig_back1_b} represent trivial basic blocks. We can always
convert a CFG of basic-blocks into a CFG of statements, if needed.
Dataflow optimization works as well with the ``collapsed'' nodes in
part \subref{fig_back4_c} as those in Figure
\subref{fig_back4_b}. Therefore, From this point forward we will work
exclusively with basic blocks, rather than individual statements.

\section{Facts \& The Meet Operator}
\label{sec_back4}
%% In & Out facts
Dataflow analysis associates every node in the CFG with two sets of
\emph{facts}. Facts describe the state of the machine before and after
execution of the statements represented by the node. \In facts
describe the machine's state beforehand, while \out facts
describe its state afterwards.

Consider Figure \ref{fig_back5}, which annotates the program fragment
in Figure \ref{fig_back1} with the value of #a#, #b#, and #c# before
and after every node. The symbol ``$\bot$'' (``bottom'') indicates an
unknown value. Assigning $\bot$ to a variable means we do not know its
value. Prior to node \ref{lst_back7_assign}, none of the variables
values' can be known, which the fact $\{a : \bot,b : \bot,c : \bot\}$
shows.  They may be set to a compiler default, a random value in
memory, or even some previous value if this fragment is embedded in a
loop. After node \ref{lst_back7_assign}, our new fact, $\{a : 1,b : 2,c : \bot\}$
shows that we know that #a# equals 1, #b# equals 2, and that we stil do not know
the value of #c#.

\afterpage{\clearpage\input{fig_back5}\clearpage}

At the entry node, we assign \inE facts a default value ($\bot$
in our example). Elsewhere, \inE facts come from predecessor
nodes. However, nodes with multiple predecessors can receive
conflicting facts. Consider the value for #c# given by nodes
\ref{lst_back7_true} and \ref{lst_back7_false}. Node
\ref{lst_back7_true} says #c# equals 4, while node
\ref{lst_back7_false} says #c# equals $a + 3$. We resolve the
situation by assigning #c# the value ``$\top$'' (``top''). As opposed
to $\bot$, $\top$ means we know a definite value for #c#, but we
cannot specify which.

The \emph{meet operator} defines how we combine facts as in the
previous situation. Table \ref{tbl_back2} shows how our meet operator,
$\sqcap$, combines facts. $v_1$ and $v_2$ represent values given to
the same variable facts by different facts. The meet operator replaces
$\bot$ with definite values, but replaces differing values with
$\top$. Though not illustrated in our example, the table also shows
that $\top$ values will always replace definite values.

\begin{table}[tbh]
  \centering
  \figbegin
  \begin{math}
    \begin{array}{cccc}
      v_1 & v_2 & v_1 \sqcap v_2 \\
      \cmidrule(r){1-1}\cmidrule(r){2-2}\cmidrule(r){3-3}
      \bot & v_2 & v_2 & \\ 
      v_1 & \bot & v_1 & \\
      \top & v_2 & \top & \\
      v_1 & \top & \top  &\\
      v_1 & v_2 & \top & \text{(when $v_1 \neq v_2$)}\\
      v_1 & v_2 & v_1 & \text{(when $v_1 = v_2$)}
    \end{array}
  \end{math}
  \caption{How the meet operator used in
    Figure \ref{fig_back5} combines facts. $v_1$ and $v_2$ are
    separate values given by separate facts to the same variable. The
    table shows how they are combined.}
  \label{tbl_back2}
  \figend
\end{table}

\section{Direction and The Transfer Function}
\label{sec_back5}
Our previous example showed \inE and \out on each
node, but did not specify how to compute those facts. For any given
analysis, we compute facts based on our \emph{analysis direction} and
\emph{transfer function}. The \emph{transfer function} specifies how we 
create facts from statements in the program. Our \emph{direction} can 
be \emph{forwards} or \emph{backwards}. A forwards analysis uses 
the transfer function to compute \out from \inE. Conversely,
a backwards analysis computes \inE using \out. 

Returning to Figure \ref{fig_back5}, we need to define a transfer
function that can be applied to each node. The transfer function does
two things:
\begin{itemize}
\item When an assignment occurs, update \out with the value of the assigned variable.
\item Otherwise, copy the variable's current value to \out.
\end{itemize}
To help define our transfer function, we define |valueOf|,
which either returns the value assigned to a variable, or its value
from \inE:
\begin{equation} |valueOf|(v) = 
  \begin{cases}
    |assign|(v) & \text{when $v$ is assigned a value in the node,} \\
    \text{\inE}(v) & \text{when $v$ is not assigned.} 
  \end{cases}
\label{eqn_back2}
\end{equation}
In the above, $v$ represents a variable; |assign| retrieves the value
assigned to that variable, if any.  Our transfer function just needs
to apply |valueOf| to all variables in \inE, as well as all
variable assignments in the node itself. If |assigned| is the set of
all assigned variables in the node, we can define how our transfer
function relates \inE and \out using set notation:
\begin{equation}
  \text{\out} = [|valueOf|(v) || v \in (\text{\inE} \cup |assigned|)].
\end{equation}

In Figure \ref{fig_back5}, we compute \out using \inE and any
assignment statements in the node: a \emph{forwards} analysis. Section
\ref{sec_back2} gives a detailed example illustrating a
\emph{backwards} analysis, computing \inE from \out. Each specific
dataflow optimization uses a certain transfer function, applied
backwards or forwards.

%% Returning to Figure \ref{fig_back5}

%% \We used a forwards analysis to compute the \out facts in Figure
%% \ref{fig_back5}.

%% Dataflow analysis applies a ``transfer function'' to each node in the
%% CFG to compute ``facts'' about the program's state before and after
%% the execution of each node. The facts computed and the transfer
%% function used depend on the specific optimization, but dataflow
%% analysis always applies them in the same way. Each node has two sets
%% of facts -- ``in'' and ``out.'' The transfer function uses the ``in''
%% facts to compute ``out'' facts for a node. ``Out'' facts on a node
%% become ``in'' facts on the node analyzed next.  If the CFG for a
%% program contains loops, then ``in'' facts for a node may change based
%% on later ``out'' facts. The transfer function will be applied
%% repeatedly until the facts stop changing -- they reach a ``fixed
%% point.''

%% Because we represent the CFG for a program as a directed graph, we can
%% choose which direction to traverse the CFG -- forwards or backwards.
%% When traversing forward, we usually compute facts about program
%% execution past a certain point (e.g., does a variable's value
%% change?); a backwards analysis computes facts up to a certain point
%% (e.g., what variables will be referenced following a given
%% statement?). Where a forwards analysis begins at the entry point(s)
%% for the CFG, a backwards analysis begins at the exit points.

\section{Iterative Analysis}
\label{sec_back6}

%% Iterative Analysis & Fixed points
As we saw in Figure \ref{fig_back5}, facts can conflict when nodes
have multiple predecessors. Even more complicated situations arise
when a program contains loops. Consider the fragment in
\ref{fig_back6}. To compute \inE on node \ref{lst_back9_test} (the
test), we need \inE for each predecessor: nodes \ref{lst_back9_assign}
(initializing #c#) and \ref{lst_back9_incr} (incrementing #c#). But
node \ref{lst_back9_incr} is also a successor of node
\ref{lst_back9_test}. How do we apply our |valueOf| function (Equation
\ref{eqn_back2}) to a graph where node X is both a successor and a
predecessor?

\begin{myfig}
\begin{tabular}{cc}
  \subfloat{\input{lst_back8}%%
    \label{fig_back6_a}} \vline &%%
  \subfloat{\input{lst_back9}%%
    \label{fig_back6_b}} \\ 
  \subref{fig_back1_a} & \subref{fig_back1_b}
\end{tabular}
\caption{\subref{fig_back6_a}: A simple C-language program with a loop. \subref{fig_back6_b}: The CFG 
for the fragment.}
\label{fig_back6}
\end{myfig}

Ironically enough, we can apply dataflow analysis to loops using \dots a
loop. That is, we apply our transfer function \emph{iteratively}, to
every node in the graph. In the case of Figure \ref{fig_back6}, we
first initialize \inE to some default. We can then use |valueOf| to
compute \out for any given node. Of course, facts will change over the
course of iteration -- especially in the case of node
\ref{lst_back9_test}. We just keep iterating until we
reach a \emph{fixed point}, meaning the facts stop changing. 

Table \ref{tbl_back3} shows \inE and \out for node \ref{lst_back9_test}, the
most interesting node in the loop. $\mathit{out}_\ref{lst_back9_test}$ represents the \out set
from the node. $\mathit{out}_\ref{lst_back9_assign}$ and $\mathit{out}_3$ are used to compute
the input set, $\mathit{in}_\ref{lst_back9_test}$ for the node. We compute $\mathit{in}_\ref{lst_back9_test}$ from
the \out facts of its predecessors, using the meet operator
defined in Section \ref{sec_back4}:
\begin{equation}
  \mathit{in}_\ref{lst_back9_test} = \mathit{out}_\ref{lst_back9_assign} \sqcap \mathit{out}_\ref{lst_back9_incr}.
\end{equation}
The zeroth iteration shows the initial
value for all sets. On the first iteration, we can see $\mathit{in}_\ref{lst_back9_test}$ equals 0:
\begin{equation}
  \begin{split}
    \mathit{in}_\ref{lst_back9_test} &= \mathit{out}_\ref{lst_back9_assign} \sqcap \mathit{out}_\ref{lst_back9_incr} \\
    &= 0 \sqcap \bot \\
    &= 0.
  \end{split}
\end{equation}
Notice that $\mathit{out}_\ref{lst_back9_incr}$ still equals $\bot$. We compute \inE and
\out in the order nodes appear in the graph. Therefore, when computing
$\mathit{in}_\ref{lst_back9_test}$, $\mathit{out}_\ref{lst_back9_incr}$ equals $\bot$. 

On the second
iteration, $\mathit{out}_\ref{lst_back9_incr}$ now equals 1 and $\mathit{out}_\ref{lst_back9_assign}$ equals
0. According to our meet operator, $\mathit{in}_\ref{lst_back9_test}$ now equals $\top$:
\begin{equation}
  \begin{split}
    \mathit{in}_\ref{lst_back9_test} &= \mathit{out}_\ref{lst_back9_assign} \sqcap \mathit{out}_\ref{lst_back9_incr} \\
    &= 0 \sqcap 1 \\
    &= \top.
  \end{split}
\end{equation}
The $\top$ value propogates through and, on the third iteration, $\mathit{out}_\ref{lst_back9_test}$ and
$\mathit{out}_\ref{lst_back9_incr}$ now equal $\top$. Facts will not change at this point so we 
stop iterating.

\begin{table}
  \centering
  \begin{math}
    \begin{array}{lcccc}
      \mathit{Iteration} & \mathit{out}_\ref{lst_back9_assign} & \mathit{out}_\ref{lst_back9_incr} & \mathit{in}_\ref{lst_back9_test} & \mathit{out}_\ref{lst_back9_test} \\
      \cmidrule(r){1-1}\cmidrule(r){2-5} %%\cmidrule(r){1-1}\cmidrule(r){1-1}\cmidrule(r){1-1} \\
      0 & \bot & \bot & \bot & \bot  \\
      1 & 0 & \bot & 0 & 0 \\
      2 & 0 & 1 & \top & \top \\
      3 & 0 & \top & \top & \top  \\
      \multicolumn{5}{c}{\dots} \\
      \multicolumn{5}{l}{\mathit{in}_\ref{lst_back9_test} = \mathit{out}_\ref{lst_back9_assign} \sqcap \mathit{out}_\ref{lst_back9_incr}} \\
      \multicolumn{5}{l}{\mathit{in}_3 = \mathit{out}_\ref{lst_back9_test}} \\
      \multicolumn{5}{l}{\mathit{out}_\ref{lst_back9_incr} = \mathit{in}_3}
    \end{array}
  \end{math}
  \caption{Iterative analysis of the CFG from Figure
    \ref{fig_back6}. We show the facts that change -- $\mathit{out}_\ref{lst_back9_test}$ in
    particular. Because node \ref{lst_back9_test} is analyzed before
    node \ref{lst_back9_incr}, $\mathit{out}_\ref{lst_back9_incr}$ ``lags''
    $\mathit{out}_\ref{lst_back9_test}$ by 1 iteration. The zeroth iteration represents the
    initial values given to \inE and \out for all nodes.}
  \figend
  \label{tbl_back3}
\end{table}

\section{Rewriting}
\label{sec_back7}

%% Rewrite based on analysis
Direction, the meet operator, facts, and the transfer function
together define the optimizing function applied by dataflow analysis
for a particular optimization. The result of the analysis is then used
to alter, or ``rewrite,'' the CFG. The meaning of the new program will
not be different than the old, but it will behave differently: execute
faster, use less memory, or whatever characteristic the optimization
should improve.

\section{Example: Dead-Code Elimination}
\label{sec_back2}

Consider Figure \ref{fig_back2}, again showing a C-language fragment.
After assignment on line \ref{fig_back2_dead_line}, #b# is not
referenced. Removing the #b# will not affect the program and,
if nothing else, will reduce the size of the program. It may even make
it run faster or use less memory. We call this optimization
\emph{dead-code elimination}.

\begin{myfig}[ht]
\begin{minipage}{1in}
  \begin{Verbatim}[numbers=left,commandchars=\\\{\}]
    a = 1;
    b = a + 1;\label{fig_back2_dead_line}
    return a + 1;
  \end{Verbatim}
\end{minipage}
\caption{A C-language fragment illustrating \emph{dead code}. After
assignment on line \ref{fig_back2_dead_line}, \verb=b= is not used
and can be considered ``dead.''}
\label{fig_back2}
\end{myfig}

Of course, people do not normally write programs with such obviously
useless statements, but other compiler optimizations can produce (or
leave behind) many such statements. \emph{Uncurrying}, described in
Chapter \ref{ref_chapter_uncurrying}, in fact depends on dead-code elimination.

To eliminate the assignment like that on line
\ref{fig_back2_dead_line}, we really need to determine which variables
are referenced after assignment. Such variables are ``live''; if a
variable is \emph{not} live, then it is dead. We use this ``liveness''
analysis to determine if a particular assignment is dead.

To determine if a variable is live, we need to know if it is
referenced after assignment.  Such variables make up the \emph{the
  live set} which we can compute between each statement. To compute
the live set, we can choose to traverse the CFG for the program forwards or
backwards.  In the forwards case, we must track each assignment and
determine, when we exit the fragment, if the variable was used
afterwards. In general we would need to track every assignment until
our traversal finished. However, if we traverse backwards, we only
need to note any reference to a variable. When we see an assignment to
a variable \emph{not} in our live set, we know it will not be
referenced afterwards. Therefore we compute ``liveness'' using a
backwards traversal over the CFG.

\begin{myfig}[th]
\begin{minipage}{2in}
\begin{Verbatim}[commandchars=\\\{\}]
       E
       ||      
       v
     -----
    ||a = 1||    \emph{live:}  \ensuremath{\emptyset}
     -----
       ||      
       V
   ---------
  ||b = a + 1||  \emph{live:} \{a\}  
   ---------
       ||      
       V
  ------------
 ||return a + 1|| \emph{live:} \{a\}
  ------------
       ||      
       X          \emph{live:}  \ensuremath{\emptyset}
\end{Verbatim}
\end{minipage}
\caption{The CFG for our example program, annotated with the live
set for each node.}
\label{fig_back3}
\end{myfig}

Figure \ref{fig_back3} shows the CFG for this example, with annotations
between each statement showing the live set. Though
execution follows the arrows in the CFG, our analysis proceeds
backwards. For example, the input to node 2 is the live set computed
for node 3 (``$\{a\}$'' in this case).

Our transfer function computes the live set based on \emph{uses} and
\emph{definitions} in a statement. Any reference (or use) of a
variable goes into the live set. Any assignment (or definition) of a
variable removes it from the live set. We can then define our transfer
function, |live|, for a statement as:

\begin{align}
  & |live|(s) = (\Varid{in}(s) \cup |use|(s)) - |def|(s), \label{eqn_back1} \\
\intertext{where}
  & s     & \text{Statement considered.} \notag\\
  & |use|(s) &  \text{Set of variables used in $s$}. \notag\\
  & |def|(s) & \text{Variable assigned to in $s$ (a singleton set)}. \notag\\
  & |in|(s) & \text{Live variables computed for $s$' successor}. \notag
\end{align}

Table \ref{tbl_back1} shows the |use| and |def| sets for each
statement. The live set computed, |live|, becomes the input, |in|, for
the statement's predecessor. We include the exit node (``#X#'') in the
table to show the initial value of |in| for the last statement --
$\emptyset$, the empty set. Our analysis then works backwards through the
program. If our program (and its CFG) contained any loops, we would
need to run this algorithm multiple times, until the live set for each
statement reached a fixed point.

\begin{table}
  \centering
  \begin{tabular}{lcccc}
    $s$ & $|use|(s)$ & $|def|(s)$ & $|in|(s)$ &  $|live|(s)$ \\
    \cmidrule(r){1-1}\cmidrule(r){2-2}\cmidrule(r){3-3}\cmidrule(r){4-4}\cmidrule(r){5-5}
    #X# & & & & $\emptyset$ \\
    #return a + 1# & $\{a\}$ & $\emptyset$ & $\emptyset$ & $\{a\}$ \\
    #b = a + 1# & $\{a\}$ & $\{b\}$ & $\{a\}$ & $\{a\}$ \\
    #a = 1# & $\emptyset$ & $\{a\}$ & $\{a\}$ & $\emptyset$ \\
    \bottomrule
  \end{tabular}
  \caption{The $|use|$, $|def|$ and $|live|$ sets computed using equation \ref{eqn_back1} for our example program.}
  \label{tbl_back1}
\end{table}

With the live set computed for each statement, our analysis can now
determine which statements to eliminate. Only nodes 1 and 2 in Figure
\ref{fig_back3} perform an assignment. The live set for node 1 (``#a = 1#'')
contains #a#, so we do not eliminate it. In node 2 (``#b = a + 1#''),
the live set does \emph{not} contain #b#. Therefore, we can eliminate
node 2, giving us a new program without any dead code:

\begin{Verbatim}
a = 1;
return a + 1;
\end{Verbatim}

\section{Summary}
\label{sec_back9}

This chapter gave an overview of \emph{dataflow optimization}. The
dataflow \emph{algorithm} gives a general technique for applying an
\emph{optimizing function} to the \emph{control flow graph} (CFG)
representing a given program. The optimizing function computes
\emph{facts} about each node in the graph, using a \emph{transfer}
function. A given analysis can proceed \emph{forwards} (where \inE
facts produce \out facts) or \emph{backwards} (where \out facts
produce \inE facts). Each optimization defines a specific \emph{meet
  operator} that combines facts for nodes with multiple predecessors
(for forwards analysis) or successors (for backwards). We compute
facts\emph{iteratively}, stopping when they reach a \emph{fixed
  point}. Finally, we \emph{rewrite} the CFG using the facts computed. The 
meaning of our program does not change, but its behavior will be ``better,'' 
whatever that means for the particular optimization applied.


%% \subsection{Basic Blocks and Control-Flow Graphs}

%% A dataflow optimization operates over a ``control-flow graph'' (CFG)
%% of the program -- a directed graph where edges encode branches or
%% jumps and nodes represent statements. Programs run by entering a node
%% from a predecessor, executing the statements in turn, and exiting the
%% node to a successor. Multiple successors imply a conditional branch,
%% though the program can only choose one. A special ``entry'' node, with
%% no predecssors, exists to give the program a starting point.

%% The statements in each node must define a ``basic block,'' which means
%% there can only be one entry and one exit to the node. Each
%% predeccessor starts at the same statement; execution cannot start in
%% the ``middle'' of the statements in the node. Each successor also
%% leaves from the same instruction, so only one ``branch'' can exist in
%% each node.

%% For example, consider the ``fall-through'' implied by the use of #case#
%% statements in this C-language program fragment:

%% \begin{verbatim}
%%   switch(i) {
%%   case 1:
%%     printf("1");
%%     break;
%%   case 2:
%%     printf("2");
%%   case 3:
%%     printf("3");
%%   }
%% \end{verbatim}

%% \begin{figure}[h]
%% \begin{verbatim}
%%    A
%%   switch   ----<-
%%   | |  |  |      |
%%   | |  |  v C    ^
%%   | |   ->case 3 |
%%   | |     |      |
%%   | |      ->----_--
%%   | | B          |  |
%%   |  ->case 2 ->-   v
%%   |                 |
%%   |   D       ----<-
%%    ->case 1  |
%%      |       v
%%      v       |
%%    --+-----<-
%%   |
%%    -> ...
%% \end{verbatim}
%% \caption{CFG illustrating \emph{fall-through} allowed by the
%%   C-language \texttt{switch} statement.}
%% \label{switchCfgEg}
%% \end{figure}

%% Figure \ref{switchCfgEg} shows a CFG for this fragment. Execution
%% begins at node A. Node C has two predeccessors: A and B. The edge
%% between Node B and C represents fall-through from the second to third
%% case. They cannot be combined because the node would need two distinct
%% entry points. Encoding a program into basic blocks usually involves
%% inserting similar branches. The CFG makes explicit control--flow that
%% exists by implication in the source program.

%% \subsection{Direction, Facts and Rewrites}

%% \subsection{Example: Bind/Return Collapse}

%% Dataflow optimizations transform the CFG representation of a program,
%% with the goal of making a faster (or smaller, or more efficient, etc.)
%% program. Dataflow computes a set of ``entry'' assumptions and ``exit''
%% facts for each node in the graph. Facts for one node become
%% assumptions for the nodes' successors (thus the term
%% ``dataflow''). The algorithm iteratves over the entire graph until a
%% fixed point is reached -- that is, facts and assumptions no longer
%% change. The computed facts can then be used to transform the graph.

%% \emph{Constant propagation example -- or something more functional?}

%% \emph{Introduce forward and backwards dataflow.}

% What does dataflow mean?

% How do you use it?

% Example

\end{document}

% LocalWords:  Dataflow dataflow CFG printf variable's CFGs ccc Uncurrying
% LocalWords:  liveness
