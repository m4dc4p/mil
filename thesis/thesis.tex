\documentclass[11pt]{article}
\usepackage{standalone}
\usepackage{comment}
%include polycode.fmt
\usepackage{sectsty}
\usepackage{palatino}
\usepackage[scaled=0.92]{helvet}
\usepackage{xspace}
\renewcommand\ttdefault{cmtt}
\allsectionsfont{\sffamily}
\usepackage{url}
\usepackage{fancyvrb}
\usepackage{setspace}
\usepackage{cmds}
\usepackage{ifthen}
\newboolean{lhs2tex}
\setboolean{lhs2tex}{true}
% Awkward Habit: Design and Optimization of A Monadic Intermediate Language
% \title{Dataflow Optimization of a Monadic Intermediate Language using Hoopl}
\title{Using Dataflow Optimization Techniques with a Monadic Intermediate Language}
%if False
\setboolean{lhs2tex}{false}
\author{Justin Bailey \\ \url{justinb@cs.pdx.edu}}
%else
\ifthenelse{\boolean{lhs2tex}}{\author{Justin Bailey \\ \url{justinb@@cs.pdx.edu}}}{}
%endif
\date{\today}

\begin{document}
\VerbatimFootnotes
\DefineShortVerb{\#}
\doublespacing

\maketitle

\begin{abstract}
  Dataflow analysis underlies a number of important optimizations
  generally implemented in compilers for imperative
  languages. Traditional intermediate representations for functional
  languages make the implementation of optimizations using dataflow
  analysis awkward and difficult. We show that, by chosing a monadic
  representation, we are able to implement several optimizations using
  dataflow analysis straightforwardly. We demonstrate several common
  optimizations, such as constant propagation and dead-code
  elimination. We implement an optimization which eliminates
  intermediate closure construction, essential to the performance of
  any functional program. Finally, we implement one of the most
  complicated dataflow-based optimizations, \emph{Lazy Code
    Motion}. To our knowledge this is the first time it has been
  implemented in a functional language compiler over a monadic
  intermediate language. Our work uses the Hoopl library to implement
  our optimizations and thus also serves as a case-study
  for advanced uses of that library.
\end{abstract}

\begin{comment}
  This thesis describes a monadic intermediate language and how we used
  the Hoopl library to implement optimizations for programs written in
  it. We show that our monadic language makes it simpler to implement
  optimizations, such as Lazy Code Motion, not normally applied to
  functional languages. We also demonstrate an optimization that can
  eliminate many intra- and inter-procedure closure allocations and
  several optimizations based on the \emph{monad laws}.
\end{comment}

% \section{Audience}

\section{Introduction/Overview}

Compilers for functional languages typically \rem{reference?}
optimize programs through \emph{algebraic rewriting}. Expressions in
the program are transformed via relations that define equivalent
expressions (except the new expression is faster, smaller, more
efficient, etc.). For example, the fizzbang \emph{monad law}:
\rem{reference}

\begin{verbatim}
  v <- return w; e 
    ==> [w/v] e (if w not in e)
\end{verbatim}

states that $w$ can be substituted for $v$ in $e$ if the conditions
above hold. A compiler that implements this law through rewriting would
recognize the first expression and replace the program with the second.

Compilers for imperitave languages, however, implement many
optimizations using \emph{dataflow analysis}. This method treats the
program as a graph, where edges represent execution paths and nodes
statements in the program. Dataflow analysis computes facts about each
node and then transforms the graph into an equivalent program (except
faster, smaller, etc.). Optimizations which use dataflow analysis
include constant propagation, dead-code elimination,
common-subexpression elimination and many others.

Dataflow analysis on imperitave programs seems natural, due to the
explicit flow-of-control from statement to statement. For pure
functional languages, with flow-of-control determined by evaluation
order, the fit seems more awkward. However, call-by-value, pure,
\emph{monadic} functional programs seem to embody the best of both
styles: expression-based evaluation \emph{and} explicit
control-flow. 

Our work, then, defines a monadic language and optimizes programs in
it using dataflow analysis. We implement a number of optimizations,
such as constant propagation and dead-code elimination. We implement
an optimization which eliminates intermediate closure construction,
showing that this technique can be used for functional-language
specific optimizations. Finally, we implement \emph{lazy code motion},
which to our knowledge has not been applied to programs in a monadic
language before.

\rem{foo}

We use the Hoopl library \rem{reference} to implement our
optimizations.  Besides showing that it is possible (and even
desirable) to use dataflow analysis in this context, our work 
also serves as a Hoopl tutorial for those interested in implementing
their own optimizations using it. 

\section{Background}
\subsection{Dataflow Optimization}

\citet{SoAndSo}\rem{Gary Kindal?} first defined dataflow
optimization techniques. They operate by transforming a
\emph{control-flow graph} (CFG) representation of a program. This
section introduces the concepts necessary to understand how dataflow
optimization works, and describes how the technique is usually
implemented.

%% A short section giving the history of dataflow optimization techniques
%% and basic concepts.

\subsubsection{Basic Blocks and Control-Flow Graphs}

A dataflow optimization operates over a ``control-flow graph'' (CFG)
of the program -- a directed graph where edges encode branches or
jumps and nodes represent statements. Programs run by entering a node
from a predecessor, executing the statements in turn, and exiting the
node to a successor. Multiple successors imply a conditional branch,
though the program can only choose one. A special ``entry'' node, with
no predecssors, exists to give the program a starting point.

The statements in each node must define a ``basic block,'' which means
there can only be one entry and one exit to the node. Each 
predeccessor starts at the same statement; execution cannot start in
the ``middle'' of the statements in the node. Each successor also
leaves from the same instruction, so only one ``branch'' can exist in
each node.

For example, consider the ``fall-through'' implied by the use of case
statements in this C language program fragment:
\begin{verbatim}
  switch(i) {
  case 1:
    printf("1");
    break;
  case 2:
    printf("2");
  case 3:
    printf("3");
  }

  printf("4");
\end{verbatim}
\begin{verbatim}
   A
  switch   ----<-
  | |  |  |      |
  | |  |  v C    ^
  | |   ->case 3 |
  | |     |      |
  | |      ->----_-- 
  | | B          |  |
  |  ->case 2 ->-   v
  |                 |
  |   D       ----<-
   ->case 1  |
     |       v
     v       |
   --------<-      
  |  E
   ->printf("3")
\end{verbatim}
Figure \ref{switchCfgEg} shows a CFG for this fragment. Execution
begins at node A. Node C has two predeccessors: A and B. The edge
between Node B and C represents fall-through from the second to third
case. They cannot be combined because the node would need two distinct
entry points. Encoding a program into basic blocks usually involves
inserting similar branches. The CFG makes explicit control--flow that
exists by implication in the source program.

\subsubsection{Dataflow over CFGs}

Dataflow optimizations transform the CFG representation of a program,
with the goal of making a faster (or smaller, or more efficient, etc.)
program. Dataflow computes a set of ``entry'' assumptions and ``exit''
facts for each node in the graph. Facts for one node become
assumptions for the nodes' successors (thus the term
``dataflow''). The algorithm operate over the entire graph until a
fixed point is reached -- that is, facts and assumptions no longer
change. The computed facts can then be used to transform the graph.

\emph{Constant propagation example -- or something more functional?}

\emph{Introduce forward and backwards dataflow.}

% What does dataflow mean?

% How do you use it? 

% Example

\subsection{Monadic Languages}

Introduce what a ``monadic'' language looks like and the advantages such a form
gives us.

\section{The Hoopl Library}

Explains the purpose of the Hoopl library and basic concepts (nodes,
graphs, rewrites and transfers)

\section{BC -- The Language of Blocks and Captures}

Defines, motivates and gives examples of the BC language.

\section{Compiling the \lamA to BC}

Demonstrates compiliation from a variant of the \lamA to BC. 

\section{Dataflow Optimization and the Hoopl Library}

Describes Hoopl and its use.

\section{Optimizing BC Programs Using Hoopl}

Catalog of optimizations implemented over BC using Hoopl.

\section{Eliminating Heap Allocation in BC using Hoopl}

Special attention to an optimization for eliminating heap allocation
in BC programs.

\section{Compiling Habit to BC to x86}

How it all came together.

\section{Conclusion \& Future Work}

\end{document}
