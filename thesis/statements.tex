\documentclass[11pt]{article}
\usepackage{url}
\usepackage{fancyvrb}
\usepackage{setspace}
\newcommand{\Ques}[1]{\noindent%
\textbf{Question:} #1}
\begin{document}
\VerbatimFootnotes
\DefineShortVerb{\#}
\doublespacing

\Ques{Can we use a monadic intermediate language to compile
  ``bare-metal'' programs such that no heap allocation occurs?}

\bigskip

I will explore efficient compilation techniques for Habit programs
using a mondaic intermediate language. My research will focus on
minimizing or eliminating the allocation of two types of data:
algebraic data types and function closures. The #prioset# example from
the Habit language report will motivate my research, as well as other
low-level core operating system algorithms.

A successful project will show that the program can be compiled such
that no heap memory gets allocated --- all data will be stored in
registers or on the stack. The code will not require special
annotations; that is, the optimizations implemented will be general
purpose. Other motivating examples will need to be found to validate
that the optimizations are truly general.

\bigskip

\Ques{How efficiently can we compile \Verb=bitdata= expressions?}

#bitdata# allows programmers to specify and manipulate bit-level
values using Haskell--like pattern matching and algebraic data
constructors. It combines the expressiveness of Haskell and the
directness of C by replacing masking, shifting and other
``bit-twiddling'' with a high-level, expressive syntax. 

This research will explore efficient code generation techniques for
#bitdata#. Two major topics will be addressed: pattern-matching on bit
patterns and constructing values using bit-level expressions. The first topic
addresses how to take bits apart, while the second looks at how to put
them back together.

Pattern-matching occurs whenever a program must branch based on bit
patterns. My research will investigate and describe different
techniques for efficient branching based on bit patterns through two
applications. The first application will take a machine language and
decode it to some form. Decoding machine language (especially for an
architecture like ARM or IA32) requires matching a huge variety of
bit-level patterns. Efficient execution will require good case
analysis. The second application will be a simulator for 1D cellular
automata. Cellular automata ``evolve'' by matching their current state
against a table of bit patterns. Each pattern specifies how the
automata should change state. Again, efficient execution will depend
on good case analysis.

Where pattern-matching takes values apart, #bitdata# constructors put
them together. The constructors replace the bitwise shifts and logical
operations found in other languages. I will research techniques for
implementing these operations correctly and efficiently. I will first
explore programs which initialize two key areas for the IA32 processor:
the global descriptor table (GDT) and the interrupt descriptor table
(IDT). While not performance critical, these areas must be initialized
precisely or the processor will halt, so the area will provide a good
test that I am implementing bitwise operations correctly.

\emph{I found two interesting pages with bit-twiddling algorithms that should be studied more: \url{http://aggregate.org/MAGIC/}, \url{http://graphics.stanford.edu/~seander/bithacks.html}.}

\end{document}
