\documentclass[12pt]{report}
%include polycode.fmt
\include{preamble}
\begin{document}
\include{document.preamble}

\chapter{Background}

%% A short section giving the history of dataflow optimization techniques
%% and basic concepts.

% Describe dataflow analysis in general terms and defines key
% concepts: basic blocks, control flow, facts, and
% rewrites. Bind/Return elimination is used as an an example.

\section{Dataflow Optimization}

The term ``program optimization'' generally refers to the idea of
transforming a program with some undesirable property to one with the
same semantics (i.e., result ) but without the unwanted property.  For
example, an optimized program may run faster, use less memory, consume
less power, or by whatever measure perform ``better'' than the
unoptimized program. Optimizations can be performed by the programmer
as part of writing a given program or they can be applied
automatically by analyzing the program and transforming it according
to an algorithm.

``Dataflow analysis'' (or ``dataflow optimization''), first introduced
by Gary Kildall \citep{Kildall1973}, refers to an algorithm for
applying an ``optimizing function'' to a given program. In itself it
does not give a specific optimization; rather, it gives a technique
for applying many different optimizations. In today's terms, dataflow
analysis treats a program as a ``control-flow graph'' (CFG), applies a
``transfer'' function to compute ``facts'' about the execution of the
program, and then applies a ``rewriting'' function to transform the
program based on those facts. Dataflow analysis is now considered
standard technique and can be found in most compilere textbooks.

The CFG for a program shows all possible execution ``paths'' that may
occur when the program runs. Nodes represent statements, while
directed edges show the order that statements may be executed.
Program execution enters the graph from one or more entry points and
leaves the graph through one or exit points.  

Figure \ref{fig_back1} gives the CFG for a C-language program
fragment.  ``#O#'' represents the entry point for the program. The
conditional statement #if(a > b)# will be executed first. Execution
can then move to either of the two following nodes, depending on the
values of #a# and #b#. Finally, execution leaves the graph through one of
the exit nodes, indicated by ``#X#'' in the diagram.

\begin{figure}[t]
\begin{Verbatim}
if(a > b)
  c = a;
else
  c = b;
\end{Verbatim}
\begin{Verbatim}
    O
    |
    v
  ---------     -----
 |if(a > b)|-->|c = a|--X
  ---------     -----
    |
    V
  -----
 |c = b|
  -----
    |
    X
\end{Verbatim}
\caption{A C-language program fragement and its associated
  control-flow graph. Notice that all possible paths are shown. Each
  specific execution of the program will depend on the values of #a#
  and #b#.}
\label{fig_back1}
\end{figure}

Dataflow analysis applies a ``transfer function'' to each node in the
CFG to compute ``facts'' about the program's state before and after
the execution of each node. The facts computed and the transfer
function used depend on the specific optimization, but dataflow
analysis always applies them in the same way. Each node has two sets
of facts -- ``in'' and ``out.'' The transfer function uses the ``in''
facts to compute ``out'' facts for a node. ``Out'' facts on a node
become ``in'' facts on its successors.  If the CFG for a program
contains loops, then ``in'' facts for a node may change based on later
``out'' facts. The transfer function will be applied repeatedly until
the facts stop changing -- they reach a ``fixed point.''

Consider Figure \ref{fig_back2}, an elaboration of Figure
\ref{fig_back1}. The program fragment now assigns values to #a# and #b#
before the condition is tested. 

\begin{figure}[t]
\begin{Verbatim}
a = 1; b = 2;

if(a > b)
  c = a;
else
  c = b;
\end{Verbatim}
\begin{Verbatim}
    O
    |
    v
  ---------
 |a = b + 1|
  ---------
    |
    V
  ---------     -----
 |if(a > b)|-->|c = a|--X
  ---------     -----
    |
    V
  -----
 |c = b|
  -----
    |
    X
\end{Verbatim}
\caption{}
\label{fig_back2}
\end{figure}

A CFG approximates execution because the graph shows \emph{all}
possible execution paths. Each specific run of the program may depend
on specific inputs, which we cannot predict. Figure \ref{fig_Back1}
shows that either the statement #c = a# or #c = b# will be
executed, but we cannot say which without knowing the values of #a# and
#b#. 


\begin{enumerate}
\item Control-flow Graph
\item Facts
\item Transfer Function
\item Rewrite Function
\item Direction
\item Meet/join operator (check reference)
\end{enumerate}

\subsection{Basic Blocks and Control-Flow Graphs}

A dataflow optimization operates over a ``control-flow graph'' (CFG)
of the program -- a directed graph where edges encode branches or
jumps and nodes represent statements. Programs run by entering a node
from a predecessor, executing the statements in turn, and exiting the
node to a successor. Multiple successors imply a conditional branch,
though the program can only choose one. A special ``entry'' node, with
no predecssors, exists to give the program a starting point.

The statements in each node must define a ``basic block,'' which means
there can only be one entry and one exit to the node. Each
predeccessor starts at the same statement; execution cannot start in
the ``middle'' of the statements in the node. Each successor also
leaves from the same instruction, so only one ``branch'' can exist in
each node.

For example, consider the ``fall-through'' implied by the use of #case#
statements in this C-language program fragment:

\begin{verbatim}
  switch(i) {
  case 1:
    printf("1");
    break;
  case 2:
    printf("2");
  case 3:
    printf("3");
  }
\end{verbatim}

\begin{figure}[h]
\begin{verbatim}
   A
  switch   ----<-
  | |  |  |      |
  | |  |  v C    ^
  | |   ->case 3 |
  | |     |      |
  | |      ->----_--
  | | B          |  |
  |  ->case 2 ->-   v
  |                 |
  |   D       ----<-
   ->case 1  |
     |       v
     v       |
   --+-----<-
  |
   -> ...
\end{verbatim}
\caption{CFG illustrating \emph{fall-through} allowed by the
  C-language \texttt{switch} statement.}
\label{switchCfgEg}
\end{figure}

Figure \ref{switchCfgEg} shows a CFG for this fragment. Execution
begins at node A. Node C has two predeccessors: A and B. The edge
between Node B and C represents fall-through from the second to third
case. They cannot be combined because the node would need two distinct
entry points. Encoding a program into basic blocks usually involves
inserting similar branches. The CFG makes explicit control--flow that
exists by implication in the source program.

\subsection{Direction, Facts and Rewrites}

\subsection{Example: Bind/Return Collapse}

Dataflow optimizations transform the CFG representation of a program,
with the goal of making a faster (or smaller, or more efficient, etc.)
program. Dataflow computes a set of ``entry'' assumptions and ``exit''
facts for each node in the graph. Facts for one node become
assumptions for the nodes' successors (thus the term
``dataflow''). The algorithm iteratves over the entire graph until a
fixed point is reached -- that is, facts and assumptions no longer
change. The computed facts can then be used to transform the graph.

\emph{Constant propagation example -- or something more functional?}

\emph{Introduce forward and backwards dataflow.}

% What does dataflow mean?

% How do you use it?

% Example

\end{document}
