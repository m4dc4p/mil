\documentclass[12pt]{report}
%include polycode.fmt
\include{preamble}
\begin{document}
\include{document.preamble}

%% Float parameters
\renewcommand{\textfraction}{0.1}
\renewcommand{\topfraction}{0.9}

\chapter{Dataflow Optimization}

%% A short section giving the history of dataflow optimization techniques
%% and basic concepts.

% Describe dataflow analysis in general terms and defines key
% concepts: basic blocks, control flow, facts, and
% rewrites. Bind/Return elimination is used as an an example.

The term ``program optimization'' generally refers to the idea of
transforming a program with some undesirable property to one with the
same semantics (i.e., result ) but without the unwanted property.  For
example, an optimized program may run faster, use less memory, consume
less power, or by whatever measure perform ``better'' than the
unoptimized program. Optimizations can be performed by the programmer
as part of writing a given program or they can be applied
automatically by analyzing the program and transforming it according
to an algorithm.

``Dataflow analysis'' (or ``dataflow optimization''), first introduced
by Gary Kildall \citep{Kildall1973}, refers to an algorithm for
applying an ``optimizing function'' to a given program. In itself it
does not give a specific optimization; rather, it gives a technique
for applying many different optimizations. In today's terms, dataflow
analysis treats a program as a ``control-flow graph'' (CFG), applies a
``transfer'' function to compute ``facts'' about the execution of the
program, and then applies a ``rewriting'' function to transform the
program based on those facts. Dataflow analysis is now considered
standard technique and can be found in most compilere textbooks.

\section{Dataflow Concepts}

The CFG for a program shows all possible execution ``paths'' that may
occur when the program runs. Nodes represent statements, while
directed edges show the order that statements may be executed.
Program execution enters the graph from one or more entry points and
leaves the graph through one or exit points.

Figure \ref{fig_back1} gives the CFG for a C-language program
fragment.  ``#E#'' represents the entry point for the program. The
conditional statement #if(a > b)# will be executed first. Execution
can then move to either of the two following nodes, depending on the
values of #a# and #b#. Finally, execution leaves the graph through one of
the exit nodes, indicated by ``#X#'' in the diagram.

\begin{figure}[th]
\centering
\figbegin

\begin{tabular}{cc}
\begin{minipage}[t]{1in}
\begin{Verbatim}[numbers=left]
if(a > b)
  c = a; 
else     
  c = b; 
\end{Verbatim}
\end{minipage} \vline & 
\begin{minipage}[t]{1in}
  \begin{Verbatim}[gobble=2]
      E
      ||
      V
    ---------        ------
    ||if(a > b)||-->||c = a||-->X
    ---------        ------
      ||
      V
     ------
    ||c = b||
     ------
      ||
      X
  \end{Verbatim}
\end{minipage} \\
 (a) & (b) \rule{0pt}{24pt}
\end{tabular}
\caption{A C-language program fragment (\emph{a}) and its associated
  control-flow graph (\emph{b}). Notice that all possible paths are
  shown in the CFG. Each specific execution of the program will
  depend on the values of \verb=a= and \verb=b=.}
\label{fig_back1}
\figend
\end{figure}

Dataflow analysis applies a ``transfer function'' to each node in the
CFG to compute ``facts'' about the program's state before and after
the execution of each node. The facts computed and the transfer
function used depend on the specific optimization, but dataflow
analysis always applies them in the same way. Each node has two sets
of facts -- ``in'' and ``out.'' The transfer function uses the ``in''
facts to compute ``out'' facts for a node. ``Out'' facts on a node
become ``in'' facts on the node analyzed next.  If the CFG for a
program contains loops, then ``in'' facts for a node may change based
on later ``out'' facts. The transfer function will be applied
repeatedly until the facts stop changing -- they reach a ``fixed
point.''

If the CFG for a program contains nodes with multiple predecessors,
``in'' facts must be combined in some way. The ``meet'' operator for
each optimization combines facts. Usually, the operator takes the
intersection or union of all the facts. Intersection implies the
analysis computes something is true for \emph{all} incoming paths. Union
implies computing something for \emph{any} incoming path.

Because we represent the CFG for a program as a directed graph, we can
choose which direction to traverse the CFG -- forwards or backwards.
When traversing forward, we usually compute facts about program
execution past a certain point (e.g., does a variable's value
change?); a backwards analysis computes facts up to a certain point
(e.g., what variables will be referenced following a given
statement?). Where a forwards analysis begins at the entry point(s)
for the CFG, a backwards analysis begins at the exit points.

Direction, the meet operator, facts, and the transfer function
together define the optimizing function applied by dataflow analysis
for a particular optimization. The result of the analysis is then used
to alter, or ``rewrite,'' the CFG. The meaning of the new program will
not be different than the old, but it will behave differently: execute
faster, use less memory, or whatever characteristic the optimization
should improve.

\section{Example: Dead-Code Elimination}

Consider Figure \ref{fig_back2}, again showing a C-language fragment.
After assignment on line \ref{fig_back2_dead_line}, #b# is not
referenced. Removing the #b# will not affect the program and,
if nothing else, will reduce the size of the program. It may even make
it run faster or use less memory. We call this optimization
\emph{dead-code elimination}.

\begin{figure}[ht]\centering
\figbegin
\begin{minipage}{1in}
  \begin{Verbatim}[numbers=left,commandchars=\\\{\}]
    a = 1;
    b = a + 1;\label{fig_back2_dead_line}
    return a + 1;
  \end{Verbatim}
\end{minipage}
\caption{A C-language fragment illustrating \emph{dead code}. After
assignment on line \ref{fig_back2_dead_line}, \verb=b= is not used
and can be considered ``dead.''}
\label{fig_back2}
\figend
\end{figure}

Of course, people do not normally write programs with such obviously
useless statements, but other compiler optimizations can produce (or
leave behind) many such statements. \emph{Uncurrying}, described in
chapter \ref{chap_uncurrying}, in fact depends on dead-code elmination.

To eliminate the assignment like that on line
\ref{fig_back2_dead_line}, we really need to determine which variables
are referenced after assignment. Such variables are ``live''; if a
variable is \emph{not} live, then it is dead. We use this ``liveness''
analysis to determine if a particular assignment is dead.

To determine if a variable is live, we need to know if it is
referenced after assignment.  Such variables make up the \emph{the
  live set} which we can compute between each statement. To compute
the live set, we can choose to traverse the CFG for the program forwards or
backwards.  In the forwards case, we must track each assignment and
determine, when we exit the fragment, if the variable was used
afterwards. In general we would need to track every assignment until
our traversal finished. However, if we traverse backwards, we only
need to note any reference to a variable. When we see an assignment to
a variable \emph{not} in our live set, we know it will not be
referenced afterwards. Therefore we compute ``liveness'' using a
backwards travesal over the CFG.

\begin{figure}[th]\centering
\figbegin
\begin{minipage}{2in}
\begin{Verbatim}[commandchars=\\\{\}]
       E
       ||      
       v
     -----
    ||a = 1||    \emph{live:}  \ensuremath{\emptyset}
     -----
       ||      
       V
   ---------
  ||b = a + 1||  \emph{live:} \{a\}  
   ---------
       ||      
       V
  ------------
 ||return a + 1|| \emph{live:} \{a\}
  ------------
       ||      
       X          \emph{live:}  \ensuremath{\emptyset}
\end{Verbatim}
\end{minipage}
\caption{The CFG for our example program, annotated with the live
set for each node.}
\label{fig_back3}
\figend
\end{figure}

Figure \ref{fig_back3} shows the CFG for this example, with annotations
between each statement showing the live set. Though
execution follows the arrows in the CFG, our analysis proceeds
backwards. For example, the input to node 2 is the live set computed
for node 3 (``$\{a\}$'' in this case).

Our transfer function computes the live set based on \emph{uses} and
\emph{definitions} in a statement. Any reference (or use) of a
variable goes into the live set. Any assignment (or definition) of a
variable removes it from the live set. We can then define our transfer
function, $live$, for a statement as:

\begin{align}
  & live(s) = (in(s) \cup use(s)) - def(s), \label{eqn_back1} \\
\intertext{where}
  & s     & \text{Statement considered.} \notag\\
  & use(s) &  \text{Set of variables used in $s$}. \notag\\
  & def(s) & \text{Variable assigned to in $s$ (a singleton set)}. \notag\\
  & in(s) & \text{Live variables computed for $s$' successor}. \notag
\end{align}

Table \ref{tbl_back1} shows the $use$ and $def$ sets for each
statement. The live set computed, $live$, becomes the input, $in$, for
the statement's predecessor. We include the exit node (``#X#'') in the
table to show the initial value of $in$ for the last statement --
$\emptyset$, the empty set. Our analysis then works backwards through the
program. If our program (and its CFG) contained any loops, we would
need to run this algorithm multiple times, until the live set for each
statement reached a fixed point.

\begin{table}
  \centering
  \begin{tabular}{lcccc}
    $s$ & $use(s)$ & $def(s)$ & $in(s)$ &  $live(s)$ \\
    \cmidrule(r){1-1}\cmidrule(r){2-2}\cmidrule(r){3-3}\cmidrule(r){4-4}\cmidrule(r){5-5}
    #X# & & & & $\emptyset$ \\
    #return a + 1# & $\{a\}$ & $\emptyset$ & $\emptyset$ & $\{a\}$ \\
    #b = a + 1# & $\{a\}$ & $\{b\}$ & $\{a\}$ & $\{a\}$ \\
    #a = 1# & $\emptyset$ & $\{a\}$ & $\{a\}$ & $\emptyset$ \\
    \bottomrule
  \end{tabular}
  \caption{The $use$, $def$ and $live$ sets computed using equation \ref{eqn_back1} for our example program.}
  \label{tbl_back1}
\end{table}

With the live set computed for each statement, our analysis can now
determine which statements to eliminate. Only nodes 1 and 2 in Figure
\ref{fig_back3} perform an assignment. The live set for node 1 (``#a = 1#'')
contains #a#, so we do not eliminate it. In node 2 (``#b = a + 1#''),
the live set does \emph{not} contain #b#. Therefore, we can eliminate
node 2, giving us a new program without any dead code:

\begin{Verbatim}
a = 1;
return a + 1;
\end{Verbatim}

\section{Conclusion}

This chapter gave an overview of \emph{dataflow optimization}, a
technique we used extensively in our work. The dataflow
\emph{algorithm} gives a general technique for applying an
\emph{optimizing function} to the \emph{control flow graph} (CFG)
representing a give program. The optimizing function computes
\emph{facts} about each node in the graph, using a \emph{transfer}
function to turn input facts into output facts. The CFG can be
traversed forwards or backwards (depending on the particular
optimization), and it may need to be traversed many times until the
computed facts reach a \emph{fixed point}.  Each optimization defines
a specific \emph{meet operator} that combines facts for nodes with
multiple inputs. Finally, the facts computed are used to
\emph{rewrite} the CFG, transforming the program so it still has the
same meaning, but behaves better, according to the optimization used.


%% \subsection{Basic Blocks and Control-Flow Graphs}

%% A dataflow optimization operates over a ``control-flow graph'' (CFG)
%% of the program -- a directed graph where edges encode branches or
%% jumps and nodes represent statements. Programs run by entering a node
%% from a predecessor, executing the statements in turn, and exiting the
%% node to a successor. Multiple successors imply a conditional branch,
%% though the program can only choose one. A special ``entry'' node, with
%% no predecssors, exists to give the program a starting point.

%% The statements in each node must define a ``basic block,'' which means
%% there can only be one entry and one exit to the node. Each
%% predeccessor starts at the same statement; execution cannot start in
%% the ``middle'' of the statements in the node. Each successor also
%% leaves from the same instruction, so only one ``branch'' can exist in
%% each node.

%% For example, consider the ``fall-through'' implied by the use of #case#
%% statements in this C-language program fragment:

%% \begin{verbatim}
%%   switch(i) {
%%   case 1:
%%     printf("1");
%%     break;
%%   case 2:
%%     printf("2");
%%   case 3:
%%     printf("3");
%%   }
%% \end{verbatim}

%% \begin{figure}[h]
%% \begin{verbatim}
%%    A
%%   switch   ----<-
%%   | |  |  |      |
%%   | |  |  v C    ^
%%   | |   ->case 3 |
%%   | |     |      |
%%   | |      ->----_--
%%   | | B          |  |
%%   |  ->case 2 ->-   v
%%   |                 |
%%   |   D       ----<-
%%    ->case 1  |
%%      |       v
%%      v       |
%%    --+-----<-
%%   |
%%    -> ...
%% \end{verbatim}
%% \caption{CFG illustrating \emph{fall-through} allowed by the
%%   C-language \texttt{switch} statement.}
%% \label{switchCfgEg}
%% \end{figure}

%% Figure \ref{switchCfgEg} shows a CFG for this fragment. Execution
%% begins at node A. Node C has two predeccessors: A and B. The edge
%% between Node B and C represents fall-through from the second to third
%% case. They cannot be combined because the node would need two distinct
%% entry points. Encoding a program into basic blocks usually involves
%% inserting similar branches. The CFG makes explicit control--flow that
%% exists by implication in the source program.

%% \subsection{Direction, Facts and Rewrites}

%% \subsection{Example: Bind/Return Collapse}

%% Dataflow optimizations transform the CFG representation of a program,
%% with the goal of making a faster (or smaller, or more efficient, etc.)
%% program. Dataflow computes a set of ``entry'' assumptions and ``exit''
%% facts for each node in the graph. Facts for one node become
%% assumptions for the nodes' successors (thus the term
%% ``dataflow''). The algorithm iteratves over the entire graph until a
%% fixed point is reached -- that is, facts and assumptions no longer
%% change. The computed facts can then be used to transform the graph.

%% \emph{Constant propagation example -- or something more functional?}

%% \emph{Introduce forward and backwards dataflow.}

% What does dataflow mean?

% How do you use it?

% Example

\end{document}
